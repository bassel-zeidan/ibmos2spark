# ibmos2spark

The package sets Spark Hadoop configurations for connecting to 
IBM Bluemix Object Storage and Softlayer Account Object Storage instances
with the swift protocol. This packages uses the new [swift2d/stocator](https://github.com/SparkTC/stocator) protocol, availble
on the latest IBM Spark Service instances (and through IBM Data Science Experience). 

One can use the swift protocol connection to read and write data that are formatted according to the 
Hadoop FileSystem format (which creates a distributed set of files in the Object Storage container).

Additionally, on may also get, put and delete individual files not in Hadoop FileSystem format.

## Installation

We are in the process of publishing a release to Maven Central. For now, a snapshot version is available. 

The `%AddJar` and `%AddDeps` magic funtion within a Scala notebook, available on IBM Spark Service in Bluemix or
Data Science Experience, will install the package.

### Spark 1.6.0 (Scala 2.10)

```scala
%AddJar https://oss.sonatype.org/content/repositories/snapshots/com/ibm/ibmos2spark/ibmos2spark_2.10/0.0.7-SNAPSHOT/ibmos2spark_2.10-0.0.7-SNAPSHOT.jar -f
```


### Spark 2.0.2 (Scala 2.11)

```scala
%AddDeps com.ibm.ibmos2spark ibmos2spark_2.11 0.0.7-SNAPSHOT --repository https://oss.sonatype.org/content/repositories/snapshots/
```


## Usage

### Bluemix


#### Setup
```scala
import com.ibm.ibmos2spark.bluemix

// The credentials HashMap may be created for you with the 
// "insert to code" link in your DSX notebook. 

var credentials = scala.collection.mutable.HashMap[String, String](
  "auth_url"->"https://identity.open.softlayer.com",
  "project_id"->"xx",
  "region"->"xx",
  "user_id"->"xx",
  "password"->"xx",
)

var container = "mycontainer"
var objectname = "mydata"
var configurationname = "bluemix_object_storage_connection"

var bmos = new bluemix(sc, configurationname, credentials)
```

#### Data to RDD / Dataframes

```scala
var rdd = sc.textFile(bmos.url(container , objectname))
```

#### GET, PUT and DELETE specific files

```scala
bmos.get(container, objectname)

var data :Array[Byte] = _
//fill data, then

bmos.put(container, objectname, data)

bmos.delete(container, objectname)
```


### Softlayer


#### Setup

```scala
import com.ibm.ibmos2spark.softlayer

var authurl = "xx"
var tenant = "xx"
var user = "xx"
var password = "xx"

var container = "mycontainer"
var objectname = "mydata"
var configurationname = "softlayerOSconnection"

var slos = new softlayer(sc, configurationname, authurl, tenant, user, password)
```

#### Data to RDD / Dataframes

```scala
var rdd = sc.textFile(slos.url(container , objectname))
```

#### GET, PUT and DELETE specific files

```scala
var somedata = slos.get(container, objectname)

var data :Array[Byte] = _
//fill data, then

slos.put(container, objectname, data)

slos.delete(container, objectname)
```

### Package Info

One can use the automatically generated object, `BuildInfo`, to obtain the package version
and other information. This object is automatically generated by the 
[`sbt-buildinfo`](https://github.com/sbt/sbt-buildinfo) plugin.

```
import com.ibm.ibmos2spark.BuildInfo

var buildstring = BuildInfo.toString
var buildbmap = BuildInfo.toMap
var buildjson = BuildInfo.toJson
``` 

## License 

Copyright 2016 IBM Cloud Data Services

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
